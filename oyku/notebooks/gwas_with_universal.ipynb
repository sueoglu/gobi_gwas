{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "992181ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas_plink import read_plink\n",
    "from limix_lmm import LMM\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3cbfe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.stats as st\n",
    "\n",
    "if not hasattr(scipy, 'dot'):\n",
    "    scipy.dot = np.dot\n",
    "if not hasattr(scipy, 'einsum'):\n",
    "    scipy.einsum = np.einsum\n",
    "if not hasattr(scipy, 'log'):\n",
    "    scipy.log = np.log\n",
    "if not hasattr(scipy, 'sign'):\n",
    "    scipy.sign = np.sign\n",
    "if not hasattr(scipy, 'sqrt'):\n",
    "    scipy.sqrt = np.sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154dc847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_pheno(X, idx_caus, var_expl, rng, direction=None):\n",
    "    # Ensure that the number of causal variant indices matches the number of variances explained.\n",
    "    assert len(idx_caus) == len(var_expl)\n",
    "\n",
    "    # If no direction is provided, randomly assign a positive or negative direction for each causal variant.\n",
    "    if direction is None:\n",
    "        direction = 2. * (rng.random(len(idx_caus)) > 0.5) - 1.\n",
    "    # Ensure that the number of directions matches the number of causal variant indices.\n",
    "    assert len(idx_caus) == len(direction)\n",
    "\n",
    "    # Compute the remaining variance after accounting for the variance explained by the causal variants.\n",
    "    ve = 1 - var_expl.sum()\n",
    "    # Ensure that the total variance explained by causal variants is less than 1.\n",
    "    assert ve > 0, 'sum(var_expl) should be < 1'\n",
    "\n",
    "    # Compute the effect sizes for the causal variants based on the variance they explain and their direction.\n",
    "    beta = np.sqrt(var_expl) * direction\n",
    "\n",
    "    # Extract the columns of X corresponding to the causal variants and standardize them.\n",
    "    Xc = X[:, idx_caus]\n",
    "    Xc = (Xc - Xc.mean(0)) / Xc.std(0)\n",
    "\n",
    "    # Compute the genetic component of the phenotype.\n",
    "    yg = Xc.dot(beta)[:, None]\n",
    "    # Compute the noise component of the phenotype.\n",
    "    yn = np.sqrt(ve) * rng.standard_normal((X.shape[0], 1))\n",
    "\n",
    "    # Sum the genetic and noise components to get the simulated phenotype.\n",
    "    y = yg + yn\n",
    "\n",
    "    # Initialize the real effect sizes for all variants in X as zeros.\n",
    "    beta_real = np.zeros(X.shape[1])\n",
    "    # Update the real effect sizes for the causal variants.\n",
    "    beta_real[idx_caus] = beta\n",
    "\n",
    "    # Standardize the phenotypic values to have mean 0 and standard deviation 1.\n",
    "    ystd = y.std()\n",
    "    y = (y - y.mean()) / ystd\n",
    "    # Adjust the real effect sizes accordingly after standardizing y.\n",
    "    beta_real = beta_real / ystd\n",
    "\n",
    "    return y, beta_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06c7ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qq_plot(p_values, title):\n",
    "    \"\"\"\n",
    "    Create a QQ plot given a list of p-values.\n",
    "\n",
    "    Parameters:\n",
    "    - p_values: list of p-values\n",
    "    - title: title for the plot\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort p-values\n",
    "    observed = -np.log10(np.sort(p_values))\n",
    "    expected = -np.log10(np.arange(1, len(p_values) + 1) / (len(p_values) + 2))\n",
    "\n",
    "    # Create the QQ plot\n",
    "    plt.scatter(expected, observed, marker='.')\n",
    "    plt.plot([0, max(expected)], [0, max(expected)], color='red', linestyle='--')\n",
    "    plt.xlabel('Expected -log10(P-value)')\n",
    "    plt.ylabel('Observed -log10(P-value)')\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950a4e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "bfile = \"/Users/oykusuoglu/gobi/gobi_gwas/universal_data/preprocessing/chr22_preprocessed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73629dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping files: 100%|██████████| 3/3 [00:00<00:00, 50.23it/s]\n",
      "/opt/anaconda3/envs/gobi_venv/lib/python3.10/site-packages/pandera/_pandas_deprecated.py:146: FutureWarning: Importing pandas-specific classes and functions from the\n",
      "top-level pandera module will be **removed in a future version of pandera**.\n",
      "If you're using pandera to validate pandas objects, we highly recommend updating\n",
      "your import:\n",
      "\n",
      "```\n",
      "# old import\n",
      "import pandera as pa\n",
      "\n",
      "# new import\n",
      "import pandera.pandas as pa\n",
      "```\n",
      "\n",
      "If you're using pandera to validate objects from other compatible libraries\n",
      "like pyspark or polars, see the supported libraries section of the documentation\n",
      "for more information on how to import pandera:\n",
      "\n",
      "https://pandera.readthedocs.io/en/stable/supported_libraries.html\n",
      "\n",
      "To disable this warning, set the environment variable:\n",
      "\n",
      "```\n",
      "export DISABLE_PANDERA_IMPORT_WARNING=True\n",
      "```\n",
      "\n",
      "  warnings.warn(_future_warning, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "bim,fam, G = read_plink(bfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02ccace2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59743, 2504)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_snps = bim.shape[0]\n",
    "n_samples = fam.shape[0]\n",
    "n_snps, n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff20aeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real = G.compute().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91916285",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_full = X_real.mean(axis=0)\n",
    "sd_full = X_real.std(axis=0, ddof=0)\n",
    "keep_full = sd_full > 1e-12\n",
    "keep_idx  = np.where(keep_full)[0] \n",
    "standardized_X = (X_real[:, keep_full] - mu_full[keep_full]) / sd_full[keep_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76720fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bim_kept = bim.iloc[keep_idx].copy().reset_index(drop=True)\n",
    "\n",
    "bim_kept[\"orig_bim_idx\"] = keep_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7e2178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = [0.1,0.2,0.3,0.4,0.5,0.6]\n",
    "n_causal = np.arange(10, 101, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9befd0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_matrix = np.zeros((len(h2), len(n_causal)))\n",
    "spearman_matrix = np.zeros((len(h2), len(n_causal)))\n",
    "count_v = 0\n",
    "count_h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "319175fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85068dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(fam))\n",
    "\n",
    "idx_train, idx_test = train_test_split(idx, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "train_ids = fam.loc[idx_train, [\"fid\",\"iid\"]].copy()\n",
    "test_ids  = fam.loc[idx_test,  [\"fid\",\"iid\"]].copy()\n",
    "\n",
    "\n",
    "train_ids.to_csv(\"/Users/oykusuoglu/gobi/gobi_gwas/oyku/data/splits/train.keep\",\n",
    "                 sep=\"\\t\", index=False, header=False)\n",
    "test_ids.to_csv(\"/Users/oykusuoglu/gobi/gobi_gwas/oyku/data/splits/test.keep\",\n",
    "                sep=\"\\t\", index=False, header=False)\n",
    "                \n",
    "\n",
    "X_train = standardized_X[idx_train]\n",
    "X_test  = standardized_X[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5efbfb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "base_dir = Path(\"/Users/oykusuoglu/gobi/gobi_gwas/oyku/plots/plots_w_new_pcs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "963a644a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gobi_venv/lib/python3.10/site-packages/limix_lmm/lmm_core.py:322: RuntimeWarning: divide by zero encountered in divide\n",
      "  ste = beta / z\n"
     ]
    }
   ],
   "source": [
    "for h in h2:\n",
    "    for n in n_causal:\n",
    "        rng = np.random.default_rng(42)\n",
    "        idx_caus_loop = rng.choice(standardized_X.shape[1], size=n, replace=False)\n",
    "        var_expl_loop = np.repeat(h/n, n)\n",
    "\n",
    "        y_loop, beta_real_loop = simulate_pheno(standardized_X, idx_caus_loop, var_expl_loop, rng)\n",
    "\n",
    "        pheno = fam[[\"fid\",\"iid\"]].copy()\n",
    "        pheno.columns = [\"FID\",\"IID\"]\n",
    "        pheno[\"y\"] = y_loop.reshape(-1)\n",
    "\n",
    "        pc_path = \"/Users/oykusuoglu/gobi/gobi_gwas/oyku/data/pca/before_qc/chr22_raw_pca10.eigenvec.zscore\"\n",
    "        pcs = pd.read_csv(pc_path, sep=r\"\\s+\", header=0, engine=\"python\")\n",
    "        pcs.columns = [\"FID\",\"IID\"] + [f\"PC{i}\" for i in range(1, pcs.shape[1]-1)]\n",
    "\n",
    "        df = pheno.merge(pcs, on=[\"FID\",\"IID\"], how=\"inner\", validate=\"one_to_one\")\n",
    "\n",
    "        k = 10\n",
    "        F = np.column_stack([np.ones((df.shape[0], 1)),\n",
    "                            df[[f\"PC{i}\" for i in range(1, k+1)]].to_numpy()])\n",
    "        \n",
    "        y_train = y_loop[idx_train]\n",
    "        y_test  = y_loop[idx_test]\n",
    "        F_train = F[idx_train]\n",
    "        F_test  = F[idx_test]\n",
    "        \n",
    "        \n",
    "        lmm = LMM(y_train, F_train)\n",
    "        lmm.process(X_train)\n",
    "        pv = lmm.getPv()\n",
    "        beta = lmm.getBetaSNP()\n",
    "        beta_ste = lmm.getBetaSNPste()\n",
    "\n",
    "        outdir = base_dir / f\"h2_{h}/causal_vars{n}\"\n",
    "        outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "        fig = plt.figure()\n",
    "        qq_plot(pv, f'QQ Plot for heritability: {h} number of causal variants: {n}')\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(outdir / f\"qq_h2_{h}_causal_vars{n}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "        x = bim_kept['pos'].values\n",
    "        fig2 = plt.figure(figsize=(10, 6))\n",
    "        ax1 = fig2.add_subplot(2, 1, 1)\n",
    "        ax2 = fig2.add_subplot(2, 1, 2, sharex=ax1)\n",
    "\n",
    "        ax1.set_title(f\"Real effect size for heritability: {h} number of causal variants: {n}\")\n",
    "        ax1.plot(x, beta_real_loop, \".k\")\n",
    "        ax1.set_ylabel(\"eff size\")\n",
    "\n",
    "        ax2.set_title(f\"GWAS results for heritability: {h} number of causal variants: {n}\")\n",
    "        ax2.plot(x, -np.log10(pv), \".k\")\n",
    "        ax2.set_ylabel(r\"-log$_{10}$ P\")\n",
    "        ax2.set_xlabel(\"position\")\n",
    "\n",
    "        fig2.tight_layout()\n",
    "        fig2.savefig(outdir / f\"effects_gwas_h2{h}_causal_vars{n}.png\",\n",
    "                    dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close(fig2)\n",
    "\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gobi_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
